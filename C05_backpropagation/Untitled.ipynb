{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e631cc2d",
   "metadata": {},
   "source": [
    "# Chapter 5. Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cdf2663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition and Multiplication node\n",
    "import numpy as np\n",
    "\n",
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        return x*y\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "        \n",
    "        return dx, dy\n",
    "    \n",
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        return x + y\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1.0\n",
    "        dy = dout * 1.0\n",
    "        \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e2a764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# Forward propagation\n",
    "apple_price = mul_apple_layer.forward(apple,apple_num)\n",
    "price = mul_tax_layer.forward(apple_price,tax)\n",
    "\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe94ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2 110.00000000000001 200\n"
     ]
    }
   ],
   "source": [
    "# Backward propagation\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(dapple, dapple_num, dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2f8a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "------------------\n",
      "110.00000000000001 2.2 3.3000000000000003 165.0 650\n"
     ]
    }
   ],
   "source": [
    "# Apple + Orange buying\n",
    "\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# Forward\n",
    "apple_price = mul_apple_layer.forward(apple,apple_num)\n",
    "orange_price = mul_orange_layer.forward(orange,orange_num)\n",
    "total_price = add_apple_orange_layer.forward(apple_price,orange_price)\n",
    "price = mul_tax_layer.forward(total_price,tax)\n",
    "\n",
    "print(price)\n",
    "print(\"------\"*3)\n",
    "\n",
    "# Backward\n",
    "dprice = 1\n",
    "dtotal_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dtotal_price)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(dapple_num, dapple, dorange, dorange_num, dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce1f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function layer\n",
    "# ReLu layer\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    # forward : if value in x is smaller or equal to 0, convert it to 0.\n",
    "    def forward(self, x):\n",
    "        self.mask = (x<=0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    # backward : if value in x at the forward <= 0, derivative is 0.\n",
    "    # else, the gradient is propagated without change of value. \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx\n",
    "\n",
    "# Sigmoid layer\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = 1. / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = dout * self.out * (1.0 - self.out)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a968efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine layer\n",
    "# output = X * W + b (weight * input + bias)\n",
    "# X : (# data, input_dim), W : (input_dim, output_dim or hidden_dim), b : output or hidden_dim\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.x = x\n",
    "        out = np.dot(x,self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        self.db = np.sum(dout, axis=0) # (N,b.size) => (b.size) : sum over N data\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        \n",
    "        return dx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e97aed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax function with loss (cross-entropy) layer\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import softmax, cross_entropy\n",
    "\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        \n",
    "    def forward(self,x,t):\n",
    "        self.y = softmax(x)\n",
    "        self.t = t\n",
    "        self.loss = cross_entropy(self.y, self.t)\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self,dout):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de145fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TwoLayer class with Layers defined above\n",
    "\n",
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_grad\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size,\n",
    "                weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "        # Layers defines here\n",
    "        # Here we use OrderedDict to set order of layers\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'],self.params['b2'])\n",
    "        \n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # Forward operation in layers.\n",
    "        # It does not execute Softmax and Loss layer propagation.\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    # t : answer label\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        # Among the output and answer label, pick the largest ones. \n",
    "        # As the value hierarchy does not change after softmax operation, \n",
    "        # we just take the maximum value index here so that we aviod additional operation.\n",
    "        y = np.argmax(y, axis=1)\n",
    "        \n",
    "        if t.ndim != 1: t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum( y == t ) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_grad(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    " \n",
    "        grads['W1'] = numerical_grad(loss_W, self.params['W1'])\n",
    "\n",
    "        grads['b1'] = numerical_grad(loss_W, self.params['b1'])\n",
    "\n",
    "        grads['W2'] = numerical_grad(loss_W, self.params['W2'])\n",
    "\n",
    "        grads['b2'] = numerical_grad(loss_W, self.params['b2'])\n",
    "\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "\n",
    "    def grad(self, x, t):\n",
    "        \n",
    "        self.loss(x, t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())[::-1]\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Affine1'].dW\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['W2'] = self.layers['Affine2'].dW\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3436051e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:4.6461922793583853e-10\n",
      "b1:2.9312840204610837e-09\n",
      "W2:6.663991405068731e-09\n",
      "b2:1.391451511206787e-07\n"
     ]
    }
   ],
   "source": [
    "# implementation test\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train) , (x_test, t_test) = \\\n",
    "    load_mnist(flatten=True, normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784,hidden_size=50,output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_grad(x_batch,t_batch)\n",
    "grad_backprop = network.grad(x_batch,t_batch)\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average(np.abs(grad_backprop[key]-grad_numerical[key]))\n",
    "    print(key + \":\" + str(diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52c5c093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.11181666666666666, 0.1109\n",
      "train acc, test acc | 0.90645, 0.9105\n",
      "train acc, test acc | 0.9259166666666667, 0.9275\n",
      "train acc, test acc | 0.9392, 0.9398\n",
      "train acc, test acc | 0.94775, 0.9449\n",
      "train acc, test acc | 0.9549666666666666, 0.9519\n",
      "train acc, test acc | 0.95845, 0.9555\n",
      "train acc, test acc | 0.9632666666666667, 0.9582\n",
      "train acc, test acc | 0.9665166666666667, 0.962\n",
      "train acc, test acc | 0.9686166666666667, 0.9629\n",
      "train acc, test acc | 0.9708333333333333, 0.9652\n",
      "train acc, test acc | 0.9713166666666667, 0.9653\n",
      "train acc, test acc | 0.9747333333333333, 0.9667\n",
      "train acc, test acc | 0.9764666666666667, 0.9693\n",
      "train acc, test acc | 0.9774, 0.9682\n",
      "train acc, test acc | 0.9791666666666666, 0.9698\n",
      "train acc, test acc | 0.978, 0.9687\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train) , (x_test, t_test) = \\\n",
    "    load_mnist(flatten=True, normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784,hidden_size=50,output_size=10)\n",
    "\n",
    "iter_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iter_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # backpropagation => gradient\n",
    "    grad = network.grad(x_batch,t_batch)\n",
    "    \n",
    "    # Updating hyperparameters\n",
    "    for key in network.params.keys():\n",
    "        network.params[key] -= learning_rate*grad[key]\n",
    "        \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train,t_train)\n",
    "        test_acc = network.accuracy(x_test,t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4506914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e60c3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
